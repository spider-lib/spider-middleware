[package]
name = "spider-middleware"
version = "0.1.8"
edition = "2024"
authors = ["mzyui <mzyui@proton.me>"]
description = "Middleware implementations for the spider-lib web scraping framework."
homepage = "https://github.com/spider-lib/spider-middleware"
repository = "https://github.com/spider-lib/spider-middleware"
license = "MIT"
readme = "README.md"
keywords = ["web-scraping", "middleware", "crawler", "scraper", "rust"]
categories = ["web-programming", "development-tools", "parsing"]

[dependencies]
async-trait = "0.1"
dashmap = { version = "6.1.0", features = ["serde"] }
governor = "0.3"
moka = { version = "0.12", features = ["future", "sync"] }
rand = { version = "0.8" }
reqwest = { version = "0.13.1", features = ["json", "native-tls"], default-features = false }
serde = { version = "1.0.228", features = ["derive"] }
serde_json = "1.0.149"
tokio = { version = "1.0", features = ["full"] }
log = "0.4"
url = { version = "2.5.8", features = ["serde"] }
bytes = { version = "1.11.1", features = ["serde"] }
bincode = { version = "1.3", optional = true }
dirs = { version = "5.0", optional = true }
cookie = { version = "0.17", optional = true }
cookie_store = { version = "0.20", optional = true }
time = { version = "0.3", features = ["serde"], optional = true }
robotstxt = { version = "0.3.0", optional = true }
ua_generator = { version = "0.5.46", optional = true }
seahash = "4.1.0"
http = "1.4.0"
hex = "0.4.3"
sha2 = "0.10.9"
spider-util = { version = "0.1.7", path = "../spider-util" }

[features]
default = ["core"]
core = []
middleware-cache = ["dep:bincode", "dep:dirs"]
middleware-proxy = []
middleware-user-agent = ["dep:ua_generator"]
middleware-robots = ["dep:robotstxt"]
middleware-cookies = ["dep:cookie", "dep:cookie_store", "dep:time"]
